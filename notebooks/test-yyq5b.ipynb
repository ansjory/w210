{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "See what BERT is all about. This version is meant to run on our server.\n",
    "\n",
    "replication of the following blog post:\n",
    "\n",
    "### News Topic Similarity Measure using Pretrained BERT Model\n",
    "\n",
    "https://medium.com/the-artificial-impostor/news-topic-similarity-measure-using-pretrained-bert-model-1dbfe6a66f1d\n",
    "\n",
    "https://github.com/ceshine/pytorch-pretrained-BERT/blob/master/notebooks/Next%20Sentence%20Prediction.ipynb\n",
    "\n",
    "https://anaconda.org/conda-forge/pytorch-pretrained-bert\n",
    "\n",
    "### various implementations of BERT\n",
    "\n",
    "https://pypi.org/project/pytorch-pretrained-bert/\n",
    "\n",
    "https://github.com/huggingface/transformers\n",
    "\n",
    "https://github.com/tensorflow/models/tree/master/official/nlp/bert\n",
    "\n",
    "https://github.com/google-research/bert\n",
    "\n",
    "https://anaconda.org/akode/bert-tensorflow\n",
    "\n",
    "using the hugging face one, is most popular in conda downloads, and is the one used by the blog author\n",
    "\n",
    "https://github.com/huggingface/pytorch-pretrained-BERT\n",
    "\n",
    "https://anaconda.org/conda-forge/pytorch-pretrained-bert\n",
    "\n",
    "\n",
    "### Understanding searches better than ever before\n",
    "\n",
    "google's white paper\n",
    "\n",
    "https://www.blog.google/products/search/search-language-understanding-bert\n",
    "\n",
    "### bert_en_uncased_L-12_H-768_A-12\n",
    "\n",
    "BERT on tensorflow hub\n",
    "\n",
    "https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Topic Similarity Measure using Pretrained BERT Model\n",
    "\n",
    "replication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Might want to add a CUDA device to the server\n",
    "\n",
    "https://www.infoworld.com/article/3299703/what-is-cuda-parallel-programming-for-gpus.html\n",
    "\n",
    "https://cloud.google.com/compute/docs/gpus/\n",
    "\n",
    "https://cloud.google.com/compute/docs/gpus/add-gpus\n",
    "\n",
    "https://cloud.google.com/products/calculator/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loads our wrapper classes\n",
    "\n",
    "we're not using NYTimes article feed\n",
    "instead of the News Title vs News Body, we have Question Title vs Question Body\n",
    "\n",
    "and we're going to make it similar to Grace's framework, so it will be easier for Chi to adapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Suggester_BertTopicSimiliarty():\n",
    "    def __init__(\n",
    "        self\n",
    "        , question_file\n",
    "        , answer_file\n",
    "        , sample_n\n",
    "        , random_state\n",
    "        , bert_cache\n",
    "        , logger\n",
    "        , device\n",
    "        , max_seq_length\n",
    "        , batch_size\n",
    "    ):\n",
    "        # initializes some vars\n",
    "        self.question_file = question_file\n",
    "        self.answer_file = answer_file\n",
    "        self.sample_n = sample_n\n",
    "        self.random_state = random_state\n",
    "        self.bert_cache = bert_cache\n",
    "        self.logger = logger\n",
    "        self.device = device\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # gets the pre-trained tokenizer\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(\n",
    "            \"bert-base-uncased\"\n",
    "            , do_lower_case = True\n",
    "            , cache_dir = self.bert_cache\n",
    "        )\n",
    "        \n",
    "        # gets the pre-trained model\n",
    "        self.model = BertForNextSentencePrediction.from_pretrained(\n",
    "            \"bert-base-uncased\"\n",
    "            , cache_dir = self.bert_cache\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # instantiates the helper class\n",
    "        self.ceshiner = Ceshiner()\n",
    "    \n",
    "    \n",
    "    def _construct_corpus(self, questions, answers):\n",
    "        '''\n",
    "        helper function that constructs corpus\n",
    "        with question id, title, accepted answer id, answer body\n",
    "        note, implicitly only questions with accepted answers will end up in corpus\n",
    "        '''\n",
    "        t1 = questions[[\n",
    "            \"id\"\n",
    "            , \"title\"\n",
    "            , \"tags\"\n",
    "            , \"accepted_answer_id\"\n",
    "        ]].rename(columns = {\n",
    "            \"id\" : \"q_id\"\n",
    "            , \"title\" : \"q_title\"\n",
    "        })\n",
    "\n",
    "        t2 = answers[[\n",
    "            \"id\"\n",
    "            , \"body\"\n",
    "            , \"images_list\"\n",
    "            , \"code_snippets\"\n",
    "            , \"cleaned_body\"\n",
    "        ]].rename(columns = {\n",
    "            \"id\" : \"a_id\"\n",
    "            , \"body\" : \"a_body\"\n",
    "            , \"images_list\" : \"a_images_list\"\n",
    "            , \"code_snippets\" : \"a_code_snippets\"\n",
    "            , \"cleaned_body\" : \"a_cleaned_body\"\n",
    "        })\n",
    "\n",
    "        t3 = t1.merge(\n",
    "            t2\n",
    "            , left_on = \"accepted_answer_id\"\n",
    "            , right_on = \"a_id\"\n",
    "            , how = \"inner\"\n",
    "        ).drop(columns = \"a_id\")\n",
    "        \n",
    "        # ... removes any cleaned answers that are null\n",
    "        t4 = t3[t3.a_cleaned_body.notnull()]\n",
    "\n",
    "        if self.sample_n is not None:\n",
    "            t5 = t4.sample(self.sample_n, random_state = self.random_state)\n",
    "        else:\n",
    "            t5 = t4\n",
    "\n",
    "        return(t5)\n",
    "    \n",
    "    \n",
    "    def prepare(self):\n",
    "        '''\n",
    "        loads data & makes corpus\n",
    "        '''\n",
    "        self.questions = pd.read_csv(self.question_file, delimiter = \"\\t\", encoding = \"utf-8\")\n",
    "        self.answers = pd.read_csv(self.answer_file, delimiter = \"\\t\", encoding = \"utf-8\")\n",
    "        self.corpus = self._construct_corpus(self.questions, self.answers)\n",
    "        print(self.corpus.shape)\n",
    "    \n",
    "    def get_similar_documents(self, query, num_results = 5, threshold = 0.10):\n",
    "        sentence_pairs = self.ceshiner.convert_sentence_pair(\n",
    "            [query] * self.corpus.shape[0]\n",
    "            , self.corpus.a_cleaned_body.tolist()\n",
    "            , max_seq_length = self.max_seq_length\n",
    "            , tokenizer = self.tokenizer\n",
    "        )\n",
    "        self.similarity_scores = self.ceshiner.eval_pairs(\n",
    "            sentence_pairs = sentence_pairs\n",
    "            , batch_size = self.batch_size\n",
    "            , model = self.model\n",
    "        )\n",
    "        similarity_above_threshold = self.similarity_scores[self.similarity_scores >= threshold]\n",
    "        res = np.argsort(similarity_above_threshold)[::-1][:num_results]\n",
    "        self.best_matches = self.corpus.iloc[res]\n",
    "        similar_que = self.best_matches[\"q_title\"]\n",
    "        similar_ans = self.best_matches[\"a_cleaned_body\"]\n",
    "        return(similar_que, similar_ans)\n",
    "\n",
    "\n",
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, target):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.target = target\n",
    "        \n",
    "        \n",
    "class Ceshiner():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def _truncate_seq_pair(self, tokens_a, tokens_b, max_length):\n",
    "        \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
    "        # This is a simple heuristic which will always truncate the longer sequence\n",
    "        # one token at a time. This makes more sense than truncating an equal percent\n",
    "        # of tokens from each, since if one sequence is very short then each token\n",
    "        # that's truncated likely contains more information than a longer sequence.\n",
    "        while True:\n",
    "            total_length = len(tokens_a) + len(tokens_b)\n",
    "            if total_length <= max_length:\n",
    "                break\n",
    "            if len(tokens_a) > len(tokens_b):\n",
    "                tokens_a.pop()\n",
    "            else:\n",
    "                tokens_b.pop()\n",
    "                \n",
    "    def convert_sentence_pair(self, titles, descs, max_seq_length, tokenizer):\n",
    "        features = []\n",
    "        for (ex_index, (title, desc)) in enumerate(zip(titles, descs)):\n",
    "            tokens_a = tokenizer.tokenize(title)\n",
    "            \n",
    "            tokens_b = None\n",
    "            tokens_b = tokenizer.tokenize(desc)\n",
    "            # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
    "            # length is less than the specified length.\n",
    "            # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
    "            self._truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
    "\n",
    "            # The convention in BERT is:\n",
    "            # (a) For sequence pairs:\n",
    "            #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
    "            #  type_ids: 0   0  0    0    0     0       0 0    1  1  1  1   1 1\n",
    "            # (b) For single sequences:\n",
    "            #  tokens:   [CLS] the dog is hairy . [SEP]\n",
    "            #  type_ids: 0   0   0   0  0     0 0\n",
    "            #\n",
    "            # Where \"type_ids\" are used to indicate whether this is the first\n",
    "            # sequence or the second sequence. The embedding vectors for `type=0` and\n",
    "            # `type=1` were learned during pre-training and are added to the wordpiece\n",
    "            # embedding vector (and position vector). This is not *strictly* necessary\n",
    "            # since the [SEP] token unambigiously separates the sequences, but it makes\n",
    "            # it easier for the model to learn the concept of sequences.\n",
    "            #\n",
    "            # For classification tasks, the first vector (corresponding to [CLS]) is\n",
    "            # used as as the \"sentence vector\". Note that this only makes sense because\n",
    "            # the entire model is fine-tuned.\n",
    "            tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\n",
    "            segment_ids = [0] * len(tokens)\n",
    "\n",
    "            if tokens_b:\n",
    "                tokens += tokens_b + [\"[SEP]\"]\n",
    "                segment_ids += [1] * (len(tokens_b) + 1)\n",
    "\n",
    "            input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "            # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "            # tokens are attended to.\n",
    "            input_mask = [1] * len(input_ids)\n",
    "\n",
    "            # Zero-pad up to the sequence length.\n",
    "            padding = [0] * (max_seq_length - len(input_ids))\n",
    "            input_ids += padding\n",
    "            input_mask += padding\n",
    "            segment_ids += padding\n",
    "\n",
    "            assert len(input_ids) == max_seq_length\n",
    "            assert len(input_mask) == max_seq_length\n",
    "            assert len(segment_ids) == max_seq_length\n",
    "\n",
    "            if ex_index < 5:\n",
    "                logger.info(\"*** Example ***\")\n",
    "                logger.info(\"tokens: %s\" % \" \".join(\n",
    "                        [str(x) for x in tokens]))\n",
    "                logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "                logger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
    "                logger.info(\n",
    "                        \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
    "\n",
    "            features.append(\n",
    "                    InputFeatures(\n",
    "                        input_ids=input_ids,\n",
    "                        input_mask=input_mask,\n",
    "                        segment_ids=segment_ids,\n",
    "                        target=1\n",
    "            ))\n",
    "        return features\n",
    "    \n",
    "    def eval_pairs(self, sentence_pairs, batch_size, model):\n",
    "        logger.info(\"***** Running evaluation *****\")\n",
    "        all_input_ids = torch.tensor([f.input_ids for f in sentence_pairs], dtype=torch.long)\n",
    "        all_input_mask = torch.tensor([f.input_mask for f in sentence_pairs], dtype=torch.long)\n",
    "        all_segment_ids = torch.tensor([f.segment_ids for f in sentence_pairs], dtype=torch.long)\n",
    "        eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids)\n",
    "        # Run prediction for full data\n",
    "        eval_sampler = SequentialSampler(eval_data)\n",
    "        eval_dataloader = DataLoader(eval_data, sampler = eval_sampler, batch_size = batch_size)\n",
    "\n",
    "        logger.info(\"  Num examples = %d\", len(sentence_pairs))\n",
    "        logger.info(\"  Batch size = %d\", batch_size)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        res = []\n",
    "\n",
    "        mb = progress_bar(eval_dataloader)\n",
    "        for input_ids, input_mask, segment_ids in mb:\n",
    "            input_ids = input_ids.to(device)\n",
    "            input_mask = input_mask.to(device)\n",
    "            segment_ids = segment_ids.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                res.append(nn.functional.softmax(\n",
    "                    model(input_ids, segment_ids, input_mask), dim=1\n",
    "                )[:, 0].detach().cpu().numpy())\n",
    "\n",
    "        res = np.concatenate(res)\n",
    "        return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/15/2019 08:54:43 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ../models/bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "11/15/2019 08:54:43 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at ../models/bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "11/15/2019 08:54:43 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file ../models/bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /tmp/tmp2bjagt38\n",
      "11/15/2019 08:54:47 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "11/15/2019 08:54:50 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForNextSentencePrediction: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    }
   ],
   "source": [
    "# i.e. app.py\n",
    "\n",
    "import gcsfs\n",
    "import os\n",
    "import logging\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "from pytorch_pretrained_bert.modeling import BertForNextSentencePrediction\n",
    "from pytorch_pretrained_bert.tokenization import BertTokenizer\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "# defines seed for replication\n",
    "SEED = 20191114\n",
    "\n",
    "# defines cache folder for BERT model\n",
    "PYTORCH_PRETRAINED_BERT_CACHE = \"../models/bert/\"\n",
    "\n",
    "SAMPLE_SIZE = 600\n",
    "BATCH_SIZE = 128\n",
    "MAX_SEQ_LENGTH = 200\n",
    "\n",
    "# creates a logger\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(\"bert\")\n",
    "\n",
    "\n",
    "# detects the device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# sets random states\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if device == torch.device(\"cuda\"):\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "\n",
    "# this uses gcsfs library\n",
    "# fs = gcsfs.GCSFileSystem(project='w210-jcgy-254100')\n",
    "# p_base_dir = \"w210-jcgy-bucket/w210-data-output-new-q-and-a-files-with-separate-cleaned-answer-bodies\"\n",
    "# p_questions = os.path.join(p_base_dir, \"PostQuestionsFiltered_V4_parsed.tsv\")\n",
    "# p_answers = os.path.join(p_base_dir, \"PostAnswersFiltered_V4_cleaned_answer_bodies.tsv\")\n",
    "# with fs.open(p_questions, 'rb') as f_q:\n",
    "#     with fs.open(p_answers, 'rb') as f_a:\n",
    "#         m = tfModel_BertTopicSimiliarty(f_q, f_a)\n",
    "\n",
    "# this relies on bucket being mounted, might be a bit faster to load the files\n",
    "p_base_dir = \"/mnt/disks/w210-jcgy-bucket/w210-data-output-new-q-and-a-files-with-separate-cleaned-answer-bodies\"\n",
    "p_questions = os.path.join(p_base_dir, \"PostQuestionsFiltered_V4_parsed.tsv\")\n",
    "p_answers = os.path.join(p_base_dir, \"PostAnswersFiltered_V4_cleaned_answer_bodies.tsv\")\n",
    "m = Suggester_BertTopicSimiliarty(\n",
    "    p_questions\n",
    "    , p_answers\n",
    "    , sample_n = SAMPLE_SIZE\n",
    "    , random_state = SEED\n",
    "    , bert_cache = PYTORCH_PRETRAINED_BERT_CACHE\n",
    "    , logger = logger\n",
    "    , device = device\n",
    "    , max_seq_length = MAX_SEQ_LENGTH\n",
    "    , batch_size = BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 8)\n"
     ]
    }
   ],
   "source": [
    "# loads data and builds a corpus\n",
    "m.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/15/2019 08:55:21 - INFO - bert -   *** Example ***\n",
      "11/15/2019 08:55:21 - INFO - bert -   tokens: [CLS] this is a query [SEP] you can add option category ##ord ##er in your v ##bar statement : i found it here : http : / / blogs . sas . com / content / graphical ##ly ##sp ##eak ##ing / 2012 / 06 / 07 / bar - chart - with - response - sort / # pretty ##ph ##oto [SEP]\n",
      "11/15/2019 08:55:21 - INFO - bert -   input_ids: 101 2023 2003 1037 23032 102 2017 2064 5587 5724 4696 8551 2121 1999 2115 1058 8237 4861 1024 1045 2179 2009 2182 1024 8299 1024 1013 1013 23012 1012 21871 1012 4012 1013 4180 1013 20477 2135 13102 25508 2075 1013 2262 1013 5757 1013 5718 1013 3347 1011 3673 1011 2007 1011 3433 1011 4066 1013 1001 3492 8458 11439 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 08:55:21 - INFO - bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 08:55:21 - INFO - bert -   segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 08:55:21 - INFO - bert -   *** Example ***\n",
      "11/15/2019 08:55:21 - INFO - bert -   tokens: [CLS] this is a query [SEP] i think using option . map would be more id ##iom ##atic : let g x = x | > into ##ption | > option . map foo | > option . map bar [SEP]\n",
      "11/15/2019 08:55:21 - INFO - bert -   input_ids: 101 2023 2003 1037 23032 102 1045 2228 2478 5724 1012 4949 2052 2022 2062 8909 18994 12070 1024 2292 1043 1060 1027 1060 1064 1028 2046 16790 1064 1028 5724 1012 4949 29379 1064 1028 5724 1012 4949 3347 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 08:55:21 - INFO - bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 08:55:21 - INFO - bert -   segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 08:55:21 - INFO - bert -   *** Example ***\n",
      "11/15/2019 08:55:21 - INFO - bert -   tokens: [CLS] this is a query [SEP] specify the key ##word argument or in your call to . [SEP]\n",
      "11/15/2019 08:55:21 - INFO - bert -   input_ids: 101 2023 2003 1037 23032 102 20648 1996 3145 18351 6685 2030 1999 2115 2655 2000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 08:55:21 - INFO - bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 08:55:21 - INFO - bert -   segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 08:55:21 - INFO - bert -   *** Example ***\n",
      "11/15/2019 08:55:21 - INFO - bert -   tokens: [CLS] this is a query [SEP] your problem is that you are using a build variable inside a release . this just isn ' t going to work , it ' s empty because it simply doesn ' t exist in a release context . even if you could do this , i wouldn ' t suggest you do this . your release should rely solely on artifacts , not build variables when the artifact was generated . you could certainly define this variable in your artifact , and access from the release , but i would highly suggest you not go down this path , as it ' s a really bad practice . you didn ' t mention it , but if you stated why you think you need access to a build variable , perhaps we could help you find a better solution here . [SEP]\n",
      "11/15/2019 08:55:21 - INFO - bert -   input_ids: 101 2023 2003 1037 23032 102 2115 3291 2003 2008 2017 2024 2478 1037 3857 8023 2503 1037 2713 1012 2023 2074 3475 1005 1056 2183 2000 2147 1010 2009 1005 1055 4064 2138 2009 3432 2987 1005 1056 4839 1999 1037 2713 6123 1012 2130 2065 2017 2071 2079 2023 1010 1045 2876 1005 1056 6592 2017 2079 2023 1012 2115 2713 2323 11160 9578 2006 10471 1010 2025 3857 10857 2043 1996 20785 2001 7013 1012 2017 2071 5121 9375 2023 8023 1999 2115 20785 1010 1998 3229 2013 1996 2713 1010 2021 1045 2052 3811 6592 2017 2025 2175 2091 2023 4130 1010 2004 2009 1005 1055 1037 2428 2919 3218 1012 2017 2134 1005 1056 5254 2009 1010 2021 2065 2017 3090 2339 2017 2228 2017 2342 3229 2000 1037 3857 8023 1010 3383 2057 2071 2393 2017 2424 1037 2488 5576 2182 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 08:55:21 - INFO - bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 08:55:21 - INFO - bert -   segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 08:55:21 - INFO - bert -   *** Example ***\n",
      "11/15/2019 08:55:21 - INFO - bert -   tokens: [CLS] this is a query [SEP] assuming your ex ##ec ##utable is named \" my _ program \" , and it ' s in the \" / foo / bar / de ##bu ##g \" directory : if you aren ' t sure how to find the program file itself , you can right - click it ( i . e . : the \" product \" ) and \" show in find ##er \" as shown in this screens ##hot : [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/15/2019 08:55:21 - INFO - bert -   input_ids: 101 2023 2003 1037 23032 102 10262 2115 4654 8586 23056 2003 2315 1000 2026 1035 2565 1000 1010 1998 2009 1005 1055 1999 1996 1000 1013 29379 1013 3347 1013 2139 8569 2290 1000 14176 1024 2065 2017 4995 1005 1056 2469 2129 2000 2424 1996 2565 5371 2993 1010 2017 2064 2157 1011 11562 2009 1006 1045 1012 1041 1012 1024 1996 1000 4031 1000 1007 1998 1000 2265 1999 2424 2121 1000 2004 3491 1999 2023 12117 12326 1024 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 08:55:21 - INFO - bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 08:55:21 - INFO - bert -   segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 08:55:22 - INFO - bert -   ***** Running evaluation *****\n",
      "11/15/2019 08:55:22 - INFO - bert -     Num examples = 600\n",
      "11/15/2019 08:55:22 - INFO - bert -     Batch size = 128\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='4' class='' max='5', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      80.00% [4/5 04:16<01:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# gets similar queries\n",
    "similar_que, similar_ans = m.get_similar_documents(query = \"this is a query\", num_results = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>q_title</th>\n",
       "      <th>tags</th>\n",
       "      <th>accepted_answer_id</th>\n",
       "      <th>a_body</th>\n",
       "      <th>a_images_list</th>\n",
       "      <th>a_code_snippets</th>\n",
       "      <th>a_cleaned_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170490</th>\n",
       "      <td>46148697</td>\n",
       "      <td>How do I order the bars of a bar chart by heig...</td>\n",
       "      <td>sasbar-chart</td>\n",
       "      <td>46151020.0</td>\n",
       "      <td>&lt;p&gt;You can add option &lt;strong&gt;categoryorder&lt;/s...</td>\n",
       "      <td>[&lt;img alt=\"enter image description here\" src=\"...</td>\n",
       "      <td>[&lt;code&gt;proc sgplot data = dat;\\r\\r\\n   vbar tx...</td>\n",
       "      <td>You can add option categoryorder in your vbar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216601</th>\n",
       "      <td>33806543</td>\n",
       "      <td>is an \"optionalized\" pipe operator idiomatic F#</td>\n",
       "      <td>f#pipelineidiomatic</td>\n",
       "      <td>33806972.0</td>\n",
       "      <td>&lt;p&gt;I think using Option.map would be more idio...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>I think using Option.map would be more idioma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123768</th>\n",
       "      <td>8396101</td>\n",
       "      <td>Invert image displayed by imshow in matplotlib</td>\n",
       "      <td>pythonimagematplotlib</td>\n",
       "      <td>8396124.0</td>\n",
       "      <td>&lt;p&gt;Specify the keyword argument &lt;code&gt;origin='...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[&lt;code&gt;origin='lower'&lt;/code&gt;, &lt;code&gt;origin='up...</td>\n",
       "      <td>Specify the keyword argument or in your call ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            q_id                                            q_title  \\\n",
       "170490  46148697  How do I order the bars of a bar chart by heig...   \n",
       "216601  33806543    is an \"optionalized\" pipe operator idiomatic F#   \n",
       "123768   8396101     Invert image displayed by imshow in matplotlib   \n",
       "\n",
       "                         tags  accepted_answer_id  \\\n",
       "170490           sasbar-chart          46151020.0   \n",
       "216601    f#pipelineidiomatic          33806972.0   \n",
       "123768  pythonimagematplotlib           8396124.0   \n",
       "\n",
       "                                                   a_body  \\\n",
       "170490  <p>You can add option <strong>categoryorder</s...   \n",
       "216601  <p>I think using Option.map would be more idio...   \n",
       "123768  <p>Specify the keyword argument <code>origin='...   \n",
       "\n",
       "                                            a_images_list  \\\n",
       "170490  [<img alt=\"enter image description here\" src=\"...   \n",
       "216601                                                 []   \n",
       "123768                                                 []   \n",
       "\n",
       "                                          a_code_snippets  \\\n",
       "170490  [<code>proc sgplot data = dat;\\r\\r\\n   vbar tx...   \n",
       "216601                                                 []   \n",
       "123768  [<code>origin='lower'</code>, <code>origin='up...   \n",
       "\n",
       "                                           a_cleaned_body  \n",
       "170490   You can add option categoryorder in your vbar...  \n",
       "216601   I think using Option.map would be more idioma...  \n",
       "123768   Specify the keyword argument or in your call ...  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.corpus.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<',\n",
       " 'p',\n",
       " '>',\n",
       " 'i',\n",
       " 'think',\n",
       " 'using',\n",
       " 'option',\n",
       " '.',\n",
       " 'map',\n",
       " 'would',\n",
       " 'be',\n",
       " 'more',\n",
       " 'id',\n",
       " '##iom',\n",
       " '##atic',\n",
       " ':',\n",
       " '<',\n",
       " '/',\n",
       " 'p',\n",
       " '>',\n",
       " '<',\n",
       " 'block',\n",
       " '##qu',\n",
       " '##ote',\n",
       " '>',\n",
       " '<',\n",
       " 'p',\n",
       " '>',\n",
       " 'let',\n",
       " 'g',\n",
       " 'x',\n",
       " '=',\n",
       " 'x',\n",
       " '|',\n",
       " '>',\n",
       " 'into',\n",
       " '##ption',\n",
       " '|',\n",
       " '>',\n",
       " 'option',\n",
       " '.',\n",
       " 'map',\n",
       " 'foo',\n",
       " '|',\n",
       " '>',\n",
       " 'option',\n",
       " '.',\n",
       " 'map',\n",
       " 'bar',\n",
       " '<',\n",
       " '/',\n",
       " 'p',\n",
       " '>',\n",
       " '<',\n",
       " '/',\n",
       " 'block',\n",
       " '##qu',\n",
       " '##ote',\n",
       " '>']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the tokenizer on the unclean answer body tends to have odd single characters\n",
    "m.tokenizer.tokenize(m.corpus.iloc[1].a_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'think',\n",
       " 'using',\n",
       " 'option',\n",
       " '.',\n",
       " 'map',\n",
       " 'would',\n",
       " 'be',\n",
       " 'more',\n",
       " 'id',\n",
       " '##iom',\n",
       " '##atic',\n",
       " ':',\n",
       " 'let',\n",
       " 'g',\n",
       " 'x',\n",
       " '=',\n",
       " 'x',\n",
       " '|',\n",
       " '>',\n",
       " 'into',\n",
       " '##ption',\n",
       " '|',\n",
       " '>',\n",
       " 'option',\n",
       " '.',\n",
       " 'map',\n",
       " 'foo',\n",
       " '|',\n",
       " '>',\n",
       " 'option',\n",
       " '.',\n",
       " 'map',\n",
       " 'bar']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.tokenizer.tokenize(m.corpus.iloc[1].a_cleaned_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/15/2019 08:48:29 - INFO - bert -   *** Example ***\n",
      "11/15/2019 08:48:29 - INFO - bert -   tokens: [CLS] how do i order the bars of a bar chart by height rather than alphabet ##ically [SEP] you can add option category ##ord ##er in your v ##bar statement : i found it here : http : / / blogs . sas . com / content / graphical ##ly ##sp ##eak ##ing / 2012 / 06 / 07 / bar - chart - with - response - sort / # pretty ##ph ##oto [SEP]\n",
      "11/15/2019 08:48:29 - INFO - bert -   input_ids: 101 2129 2079 1045 2344 1996 6963 1997 1037 3347 3673 2011 4578 2738 2084 12440 15004 102 2017 2064 5587 5724 4696 8551 2121 1999 2115 1058 8237 4861 1024 1045 2179 2009 2182 1024 8299 1024 1013 1013 23012 1012 21871 1012 4012 1013 4180 1013 20477 2135 13102 25508 2075 1013 2262 1013 5757 1013 5718 1013 3347 1011 3673 1011 2007 1011 3433 1011 4066 1013 1001 3492 8458 11439 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 08:48:29 - INFO - bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 08:48:29 - INFO - bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 08:48:29 - INFO - bert -   *** Example ***\n",
      "11/15/2019 08:48:29 - INFO - bert -   tokens: [CLS] is an \" optional ##ized \" pipe operator id ##iom ##atic f # [SEP] i think using option . map would be more id ##iom ##atic : let g x = x | > into ##ption | > option . map foo | > option . map bar [SEP]\n",
      "11/15/2019 08:48:29 - INFO - bert -   input_ids: 101 2003 2019 1000 11887 3550 1000 8667 6872 8909 18994 12070 1042 1001 102 1045 2228 2478 5724 1012 4949 2052 2022 2062 8909 18994 12070 1024 2292 1043 1060 1027 1060 1064 1028 2046 16790 1064 1028 5724 1012 4949 29379 1064 1028 5724 1012 4949 3347 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 08:48:29 - INFO - bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 08:48:29 - INFO - bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 08:48:29 - INFO - bert -   *** Example ***\n",
      "11/15/2019 08:48:29 - INFO - bert -   tokens: [CLS] in ##vert image displayed by im ##sho ##w in mat ##pl ##ot ##lib [SEP] specify the key ##word argument or in your call to . [SEP]\n",
      "11/15/2019 08:48:29 - INFO - bert -   input_ids: 101 1999 16874 3746 6913 2011 10047 22231 2860 1999 13523 24759 4140 29521 102 20648 1996 3145 18351 6685 2030 1999 2115 2655 2000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 08:48:29 - INFO - bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 08:48:29 - INFO - bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 08:48:29 - INFO - bert -   *** Example ***\n",
      "11/15/2019 08:48:29 - INFO - bert -   tokens: [CLS] powers ##hell script running in vs ##ts release not recognizing environment variables [SEP] your problem is that you are using a build variable inside a release . this just isn ' t going to work , it ' s empty because it simply doesn ' t exist in a release context . even if you could do this , i wouldn ' t suggest you do this . your release should rely solely on artifacts , not build variables when the artifact was generated . you could certainly define this variable in your artifact , and access from the release , but i would highly suggest you not go down this path , as it ' s a really bad practice . you didn ' t mention it , but if you stated why you think you need access to a build variable , perhaps we could help you find a better solution here . [SEP]\n",
      "11/15/2019 08:48:29 - INFO - bert -   input_ids: 101 4204 18223 5896 2770 1999 5443 3215 2713 2025 14622 4044 10857 102 2115 3291 2003 2008 2017 2024 2478 1037 3857 8023 2503 1037 2713 1012 2023 2074 3475 1005 1056 2183 2000 2147 1010 2009 1005 1055 4064 2138 2009 3432 2987 1005 1056 4839 1999 1037 2713 6123 1012 2130 2065 2017 2071 2079 2023 1010 1045 2876 1005 1056 6592 2017 2079 2023 1012 2115 2713 2323 11160 9578 2006 10471 1010 2025 3857 10857 2043 1996 20785 2001 7013 1012 2017 2071 5121 9375 2023 8023 1999 2115 20785 1010 1998 3229 2013 1996 2713 1010 2021 1045 2052 3811 6592 2017 2025 2175 2091 2023 4130 1010 2004 2009 1005 1055 1037 2428 2919 3218 1012 2017 2134 1005 1056 5254 2009 1010 2021 2065 2017 3090 2339 2017 2228 2017 2342 3229 2000 1037 3857 8023 1010 3383 2057 2071 2393 2017 2424 1037 2488 5576 2182 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 08:48:29 - INFO - bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 08:48:29 - INFO - bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/15/2019 08:48:29 - INFO - bert -   *** Example ***\n",
      "11/15/2019 08:48:29 - INFO - bert -   tokens: [CLS] x ##code command line tool - how to run in terminal ? [SEP] assuming your ex ##ec ##utable is named \" my _ program \" , and it ' s in the \" / foo / bar / de ##bu ##g \" directory : if you aren ' t sure how to find the program file itself , you can right - click it ( i . e . : the \" product \" ) and \" show in find ##er \" as shown in this screens ##hot : [SEP]\n",
      "11/15/2019 08:48:29 - INFO - bert -   input_ids: 101 1060 16044 3094 2240 6994 1011 2129 2000 2448 1999 5536 1029 102 10262 2115 4654 8586 23056 2003 2315 1000 2026 1035 2565 1000 1010 1998 2009 1005 1055 1999 1996 1000 1013 29379 1013 3347 1013 2139 8569 2290 1000 14176 1024 2065 2017 4995 1005 1056 2469 2129 2000 2424 1996 2565 5371 2993 1010 2017 2064 2157 1011 11562 2009 1006 1045 1012 1041 1012 1024 1996 1000 4031 1000 1007 1998 1000 2265 1999 2424 2121 1000 2004 3491 1999 2023 12117 12326 1024 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 08:48:29 - INFO - bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 08:48:29 - INFO - bert -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "sentence_pairs = m.ceshiner.convert_sentence_pair(\n",
    "    titles = m.corpus.q_title.tolist()\n",
    "    , descs = m.corpus.a_cleaned_body.tolist()\n",
    "    , max_seq_length = 200\n",
    "    , tokenizer = m.tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9999635 , 0.9999807 , 0.99998915, 0.99990284, 0.9999708 ,\n",
       "       0.9999167 , 0.99996996, 0.99998784, 0.99990034, 0.99997663],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.similarity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/15/2019 07:35:07 - INFO - bert -   *** Example ***\n",
      "11/15/2019 07:35:07 - INFO - bert -   tokens: [CLS] this is a query [SEP] you can add option category ##ord ##er in your v ##bar statement : i found it here : http : / / blogs . sas . com / content / graphical ##ly ##sp ##eak ##ing / 2012 / 06 / 07 / bar - chart - with - response - sort / # pretty ##ph ##oto [SEP]\n",
      "11/15/2019 07:35:07 - INFO - bert -   input_ids: 101 2023 2003 1037 23032 102 2017 2064 5587 5724 4696 8551 2121 1999 2115 1058 8237 4861 1024 1045 2179 2009 2182 1024 8299 1024 1013 1013 23012 1012 21871 1012 4012 1013 4180 1013 20477 2135 13102 25508 2075 1013 2262 1013 5757 1013 5718 1013 3347 1011 3673 1011 2007 1011 3433 1011 4066 1013 1001 3492 8458 11439 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 07:35:07 - INFO - bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 07:35:07 - INFO - bert -   segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 07:35:08 - INFO - bert -   *** Example ***\n",
      "11/15/2019 07:35:08 - INFO - bert -   tokens: [CLS] this is a query [SEP] i think using option . map would be more id ##iom ##atic : let g x = x | > into ##ption | > option . map foo | > option . map bar [SEP]\n",
      "11/15/2019 07:35:08 - INFO - bert -   input_ids: 101 2023 2003 1037 23032 102 1045 2228 2478 5724 1012 4949 2052 2022 2062 8909 18994 12070 1024 2292 1043 1060 1027 1060 1064 1028 2046 16790 1064 1028 5724 1012 4949 29379 1064 1028 5724 1012 4949 3347 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 07:35:08 - INFO - bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 07:35:08 - INFO - bert -   segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 07:35:08 - INFO - bert -   *** Example ***\n",
      "11/15/2019 07:35:08 - INFO - bert -   tokens: [CLS] this is a query [SEP] specify the key ##word argument or in your call to . [SEP]\n",
      "11/15/2019 07:35:08 - INFO - bert -   input_ids: 101 2023 2003 1037 23032 102 20648 1996 3145 18351 6685 2030 1999 2115 2655 2000 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 07:35:08 - INFO - bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 07:35:08 - INFO - bert -   segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 07:35:08 - INFO - bert -   *** Example ***\n",
      "11/15/2019 07:35:08 - INFO - bert -   tokens: [CLS] this is a query [SEP] your problem is that you are using a build variable inside a release . this just isn ' t going to work , it ' s empty because it simply doesn ' t exist in a release context . even if you could do this , i wouldn ' t suggest you do this . your release should rely solely on artifacts , not build variables when the artifact was generated . you could certainly define this variable in your artifact , and access from the release , but i would highly suggest you not go down this path , as it ' s a really bad practice . you didn ' t mention it , but if you stated why you think you need access to a build variable , perhaps we could help you find a better solution here . [SEP]\n",
      "11/15/2019 07:35:08 - INFO - bert -   input_ids: 101 2023 2003 1037 23032 102 2115 3291 2003 2008 2017 2024 2478 1037 3857 8023 2503 1037 2713 1012 2023 2074 3475 1005 1056 2183 2000 2147 1010 2009 1005 1055 4064 2138 2009 3432 2987 1005 1056 4839 1999 1037 2713 6123 1012 2130 2065 2017 2071 2079 2023 1010 1045 2876 1005 1056 6592 2017 2079 2023 1012 2115 2713 2323 11160 9578 2006 10471 1010 2025 3857 10857 2043 1996 20785 2001 7013 1012 2017 2071 5121 9375 2023 8023 1999 2115 20785 1010 1998 3229 2013 1996 2713 1010 2021 1045 2052 3811 6592 2017 2025 2175 2091 2023 4130 1010 2004 2009 1005 1055 1037 2428 2919 3218 1012 2017 2134 1005 1056 5254 2009 1010 2021 2065 2017 3090 2339 2017 2228 2017 2342 3229 2000 1037 3857 8023 1010 3383 2057 2071 2393 2017 2424 1037 2488 5576 2182 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 07:35:08 - INFO - bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 07:35:08 - INFO - bert -   segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 07:35:08 - INFO - bert -   *** Example ***\n",
      "11/15/2019 07:35:08 - INFO - bert -   tokens: [CLS] this is a query [SEP] assuming your ex ##ec ##utable is named \" my _ program \" , and it ' s in the \" / foo / bar / de ##bu ##g \" directory : if you aren ' t sure how to find the program file itself , you can right - click it ( i . e . : the \" product \" ) and \" show in find ##er \" as shown in this screens ##hot : [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/15/2019 07:35:08 - INFO - bert -   input_ids: 101 2023 2003 1037 23032 102 10262 2115 4654 8586 23056 2003 2315 1000 2026 1035 2565 1000 1010 1998 2009 1005 1055 1999 1996 1000 1013 29379 1013 3347 1013 2139 8569 2290 1000 14176 1024 2065 2017 4995 1005 1056 2469 2129 2000 2424 1996 2565 5371 2993 1010 2017 2064 2157 1011 11562 2009 1006 1045 1012 1041 1012 1024 1996 1000 4031 1000 1007 1998 1000 2265 1999 2424 2121 1000 2004 3491 1999 2023 12117 12326 1024 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 07:35:08 - INFO - bert -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/15/2019 07:35:08 - INFO - bert -   segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "sentence_pairs_2 = m.ceshiner.convert_sentence_pair(\n",
    "    titles = [\"this is a query\"] * m.corpus.shape[0]\n",
    "    , descs = m.corpus.a_cleaned_body.tolist()\n",
    "    , max_seq_length = 200\n",
    "    , tokenizer = m.tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.InputFeatures at 0x7f55d7671110>,\n",
       " <__main__.InputFeatures at 0x7f55f7f2e210>,\n",
       " <__main__.InputFeatures at 0x7f55ecca9090>,\n",
       " <__main__.InputFeatures at 0x7f55f9f30990>,\n",
       " <__main__.InputFeatures at 0x7f55ecca9290>,\n",
       " <__main__.InputFeatures at 0x7f55d4f749d0>,\n",
       " <__main__.InputFeatures at 0x7f55ecca9610>,\n",
       " <__main__.InputFeatures at 0x7f55d4f74bd0>,\n",
       " <__main__.InputFeatures at 0x7f55f2558550>,\n",
       " <__main__.InputFeatures at 0x7f55f2558910>]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_pairs_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_pairs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123768       Invert image displayed by imshow in matplotlib\n",
      "47204     How to perform undirected graph processing fro...\n",
      "216601      is an \"optionalized\" pipe operator idiomatic F#\n",
      "170929                          ChartJS with Dynamic Colors\n",
      "78853     Xcode command line tool - how to run in terminal?\n",
      "Name: q_title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(similar_que)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123768     Specify the keyword argument or in your call ...\n",
      "47204      Ok, here's my stab at the problem. Here's a s...\n",
      "216601     I think using Option.map would be more idioma...\n",
      "170929     You are looking for something like the follow...\n",
      "78853      Assuming your executable is named \"my_program...\n",
      "Name: a_cleaned_body, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(similar_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(m.similarity_scores, bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 1.0, 0.0)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(m.similarity_scores > 0.99) / len(m.similarity_scores), sum(m.similarity_scores > 0.9) / len(m.similarity_scores), sum(m.similarity_scores < 0.5) / len(m.similarity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q_id</th>\n",
       "      <th>q_title</th>\n",
       "      <th>tags</th>\n",
       "      <th>accepted_answer_id</th>\n",
       "      <th>a_body</th>\n",
       "      <th>a_images_list</th>\n",
       "      <th>a_code_snippets</th>\n",
       "      <th>a_cleaned_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>123768</th>\n",
       "      <td>8396101</td>\n",
       "      <td>Invert image displayed by imshow in matplotlib</td>\n",
       "      <td>pythonimagematplotlib</td>\n",
       "      <td>8396124.0</td>\n",
       "      <td>&lt;p&gt;Specify the keyword argument &lt;code&gt;origin='...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[&lt;code&gt;origin='lower'&lt;/code&gt;, &lt;code&gt;origin='up...</td>\n",
       "      <td>Specify the keyword argument or in your call ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47204</th>\n",
       "      <td>2807151</td>\n",
       "      <td>How to perform undirected graph processing fro...</td>\n",
       "      <td>sqlgraphactivemq</td>\n",
       "      <td>2807579.0</td>\n",
       "      <td>&lt;p&gt;Ok, here's my stab at the problem. &lt;/p&gt;\\r\\r...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[&lt;code&gt;[nodes]\\r\\r\\nnode : varchar(xx)\\r\\r\\n\\r...</td>\n",
       "      <td>Ok, here's my stab at the problem. Here's a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216601</th>\n",
       "      <td>33806543</td>\n",
       "      <td>is an \"optionalized\" pipe operator idiomatic F#</td>\n",
       "      <td>f#pipelineidiomatic</td>\n",
       "      <td>33806972.0</td>\n",
       "      <td>&lt;p&gt;I think using Option.map would be more idio...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>I think using Option.map would be more idioma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170929</th>\n",
       "      <td>46118401</td>\n",
       "      <td>ChartJS with Dynamic Colors</td>\n",
       "      <td>chart.js</td>\n",
       "      <td>46118932.0</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;You are looking for something like ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[&lt;code&gt;var chart = new Chart(ctx, {\\r\\r\\n   ty...</td>\n",
       "      <td>You are looking for something like the follow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78853</th>\n",
       "      <td>19554822</td>\n",
       "      <td>Xcode command line tool - how to run in terminal?</td>\n",
       "      <td>xcodecommand-line</td>\n",
       "      <td>19554870.0</td>\n",
       "      <td>&lt;p&gt;Assuming your executable is named \"my_progr...</td>\n",
       "      <td>[&lt;img alt=\"enter image description here\" src=\"...</td>\n",
       "      <td>[&lt;code&gt;cd /foo/bar\\r\\r\\n./my_program\\r\\r\\n&lt;/co...</td>\n",
       "      <td>Assuming your executable is named \"my_program...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            q_id                                            q_title  \\\n",
       "123768   8396101     Invert image displayed by imshow in matplotlib   \n",
       "47204    2807151  How to perform undirected graph processing fro...   \n",
       "216601  33806543    is an \"optionalized\" pipe operator idiomatic F#   \n",
       "170929  46118401                        ChartJS with Dynamic Colors   \n",
       "78853   19554822  Xcode command line tool - how to run in terminal?   \n",
       "\n",
       "                         tags  accepted_answer_id  \\\n",
       "123768  pythonimagematplotlib           8396124.0   \n",
       "47204        sqlgraphactivemq           2807579.0   \n",
       "216601    f#pipelineidiomatic          33806972.0   \n",
       "170929               chart.js          46118932.0   \n",
       "78853       xcodecommand-line          19554870.0   \n",
       "\n",
       "                                                   a_body  \\\n",
       "123768  <p>Specify the keyword argument <code>origin='...   \n",
       "47204   <p>Ok, here's my stab at the problem. </p>\\r\\r...   \n",
       "216601  <p>I think using Option.map would be more idio...   \n",
       "170929  <p><strong>You are looking for something like ...   \n",
       "78853   <p>Assuming your executable is named \"my_progr...   \n",
       "\n",
       "                                            a_images_list  \\\n",
       "123768                                                 []   \n",
       "47204                                                  []   \n",
       "216601                                                 []   \n",
       "170929                                                 []   \n",
       "78853   [<img alt=\"enter image description here\" src=\"...   \n",
       "\n",
       "                                          a_code_snippets  \\\n",
       "123768  [<code>origin='lower'</code>, <code>origin='up...   \n",
       "47204   [<code>[nodes]\\r\\r\\nnode : varchar(xx)\\r\\r\\n\\r...   \n",
       "216601                                                 []   \n",
       "170929  [<code>var chart = new Chart(ctx, {\\r\\r\\n   ty...   \n",
       "78853   [<code>cd /foo/bar\\r\\r\\n./my_program\\r\\r\\n</co...   \n",
       "\n",
       "                                           a_cleaned_body  \n",
       "123768   Specify the keyword argument or in your call ...  \n",
       "47204    Ok, here's my stab at the problem. Here's a s...  \n",
       "216601   I think using Option.map would be more idioma...  \n",
       "170929   You are looking for something like the follow...  \n",
       "78853    Assuming your executable is named \"my_program...  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.best_matches"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
